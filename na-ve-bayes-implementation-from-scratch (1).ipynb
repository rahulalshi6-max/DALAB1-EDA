{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06737d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:03.017132Z",
     "iopub.status.busy": "2022-03-27T15:15:03.015869Z",
     "iopub.status.idle": "2022-03-27T15:15:04.207222Z",
     "shell.execute_reply": "2022-03-27T15:15:04.206395Z",
     "shell.execute_reply.started": "2022-03-27T14:34:58.078678Z"
    },
    "papermill": {
     "duration": 1.220724,
     "end_time": "2022-03-27T15:15:04.207393",
     "exception": false,
     "start_time": "2022-03-27T15:15:02.986669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969d1401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:04.266613Z",
     "iopub.status.busy": "2022-03-27T15:15:04.265805Z",
     "iopub.status.idle": "2022-03-27T15:15:04.316692Z",
     "shell.execute_reply": "2022-03-27T15:15:04.317220Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.191717Z"
    },
    "papermill": {
     "duration": 0.082802,
     "end_time": "2022-03-27T15:15:04.317390",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.234588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  5572 non-null   object\n",
      " 1   Message   5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# load data and get some basic information about it...\n",
    "df = pd.read_csv('SPAM text message 20170820 - Data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c6b204",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:04.376357Z",
     "iopub.status.busy": "2022-03-27T15:15:04.375372Z",
     "iopub.status.idle": "2022-03-27T15:15:04.390475Z",
     "shell.execute_reply": "2022-03-27T15:15:04.391009Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.251800Z"
    },
    "papermill": {
     "duration": 0.046454,
     "end_time": "2022-03-27T15:15:04.391185",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.344731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's show how the dataset look like.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc86f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:04.449916Z",
     "iopub.status.busy": "2022-03-27T15:15:04.448860Z",
     "iopub.status.idle": "2022-03-27T15:15:04.458149Z",
     "shell.execute_reply": "2022-03-27T15:15:04.457441Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.272620Z"
    },
    "papermill": {
     "duration": 0.03968,
     "end_time": "2022-03-27T15:15:04.458294",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.418614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentages of Category column categories: \n",
      "ham     86.593683\n",
      "spam    13.406317\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('percentages of Category column categories: ')\n",
    "print(df['Category'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca7223",
   "metadata": {
    "papermill": {
     "duration": 0.027984,
     "end_time": "2022-03-27T15:15:04.514293",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.486309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1> Split Data into Train / Validation Datasets </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a639b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:04.576720Z",
     "iopub.status.busy": "2022-03-27T15:15:04.576040Z",
     "iopub.status.idle": "2022-03-27T15:15:04.581795Z",
     "shell.execute_reply": "2022-03-27T15:15:04.582359Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.283271Z"
    },
    "papermill": {
     "duration": 0.040251,
     "end_time": "2022-03-27T15:15:04.582531",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.542280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df['Message'],df['Category'],\n",
    "                                               test_size=0.2,random_state=42)\n",
    "training_set=pd.concat([x_train,y_train],axis=1)\n",
    "testing_set=pd.concat([x_test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7038560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:04.643068Z",
     "iopub.status.busy": "2022-03-27T15:15:04.642398Z",
     "iopub.status.idle": "2022-03-27T15:15:04.648635Z",
     "shell.execute_reply": "2022-03-27T15:15:04.649494Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.296889Z"
    },
    "papermill": {
     "duration": 0.037715,
     "end_time": "2022-03-27T15:15:04.649802",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.612087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape:  (4457, 2)\n",
      "testing set shape:  (1115, 2)\n"
     ]
    }
   ],
   "source": [
    "print('training set shape: ',training_set.shape)\n",
    "print('testing set shape: ',testing_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8e646c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:04.717863Z",
     "iopub.status.busy": "2022-03-27T15:15:04.717198Z",
     "iopub.status.idle": "2022-03-27T15:15:04.719957Z",
     "shell.execute_reply": "2022-03-27T15:15:04.720472Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.304227Z"
    },
    "papermill": {
     "duration": 0.042082,
     "end_time": "2022-03-27T15:15:04.720650",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.678568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentages of Category column categories in Training Dataset: \n",
      " ham     86.582903\n",
      "spam    13.417097\n",
      "Name: Category, dtype: float64\n",
      "percentages of Category column categories in Validation Dataset: \n",
      " ham     86.636771\n",
      "spam    13.363229\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('percentages of Category column categories in Training Dataset: \\n',training_set['Category'].value_counts(normalize=True)*100)\n",
    "print('percentages of Category column categories in Validation Dataset: \\n',testing_set['Category'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412ebd2",
   "metadata": {
    "papermill": {
     "duration": 0.03083,
     "end_time": "2022-03-27T15:15:04.782101",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.751271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p>we notice here that training_set & testing_set have the same percentages of the original dataframe</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b451a05",
   "metadata": {
    "papermill": {
     "duration": 0.030859,
     "end_time": "2022-03-27T15:15:04.843530",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.812671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1> Text Processing and Data Cleaning </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12100091",
   "metadata": {
    "papermill": {
     "duration": 0.028083,
     "end_time": "2022-03-27T15:15:04.902182",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.874099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p> let's now remove any non-word character and lowercasing the letters. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc7e5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:04.964152Z",
     "iopub.status.busy": "2022-03-27T15:15:04.963513Z",
     "iopub.status.idle": "2022-03-27T15:15:05.030577Z",
     "shell.execute_reply": "2022-03-27T15:15:05.029988Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.320195Z"
    },
    "papermill": {
     "duration": 0.09921,
     "end_time": "2022-03-27T15:15:05.030718",
     "exception": false,
     "start_time": "2022-03-27T15:15:04.931508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "training_set['Message'] = training_set['Message'].str.replace('\\W', ' ')\n",
    "testing_set['Message'] = testing_set['Message'].str.replace('\\W', ' ')\n",
    "training_set['Message'] = training_set['Message'].str.lower()\n",
    "testing_set['Message'] = testing_set['Message'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038583d4",
   "metadata": {
    "papermill": {
     "duration": 0.029698,
     "end_time": "2022-03-27T15:15:05.089509",
     "exception": false,
     "start_time": "2022-03-27T15:15:05.059811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p> and also split the statments into words. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e214734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:05.151977Z",
     "iopub.status.busy": "2022-03-27T15:15:05.151024Z",
     "iopub.status.idle": "2022-03-27T15:15:05.170116Z",
     "shell.execute_reply": "2022-03-27T15:15:05.169549Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.391931Z"
    },
    "papermill": {
     "duration": 0.051759,
     "end_time": "2022-03-27T15:15:05.170266",
     "exception": false,
     "start_time": "2022-03-27T15:15:05.118507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set['Message']=training_set['Message'].str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532be75f",
   "metadata": {
    "papermill": {
     "duration": 0.029213,
     "end_time": "2022-03-27T15:15:05.228350",
     "exception": false,
     "start_time": "2022-03-27T15:15:05.199137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p> now let's tokenize the statements, although you can use NLTK or Spacy to tokenize the statements but I am going to tokenize them from scratch. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19e41ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:05.295019Z",
     "iopub.status.busy": "2022-03-27T15:15:05.294300Z",
     "iopub.status.idle": "2022-03-27T15:15:05.310708Z",
     "shell.execute_reply": "2022-03-27T15:15:05.310172Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.415495Z"
    },
    "papermill": {
     "duration": 0.053581,
     "end_time": "2022-03-27T15:15:05.310856",
     "exception": false,
     "start_time": "2022-03-27T15:15:05.257275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1- collecting all of the words in all messages....\n",
    "vocab=[]\n",
    "for lst in training_set['Message']:\n",
    "    for i in lst:\n",
    "        vocab.append(i)\n",
    "vocab=list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53eadafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:05.445197Z",
     "iopub.status.busy": "2022-03-27T15:15:05.439792Z",
     "iopub.status.idle": "2022-03-27T15:15:20.150692Z",
     "shell.execute_reply": "2022-03-27T15:15:20.150084Z",
     "shell.execute_reply.started": "2022-03-27T14:34:59.444753Z"
    },
    "papermill": {
     "duration": 14.81087,
     "end_time": "2022-03-27T15:15:20.150848",
     "exception": false,
     "start_time": "2022-03-27T15:15:05.339978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Category</th>\n",
       "      <th>visiting</th>\n",
       "      <th>mist</th>\n",
       "      <th>timing</th>\n",
       "      <th>flowing</th>\n",
       "      <th>spoilt</th>\n",
       "      <th>torch</th>\n",
       "      <th>jod</th>\n",
       "      <th>stream</th>\n",
       "      <th>...</th>\n",
       "      <th>msn</th>\n",
       "      <th>doggin</th>\n",
       "      <th>abta</th>\n",
       "      <th>use</th>\n",
       "      <th>07808726822</th>\n",
       "      <th>grace</th>\n",
       "      <th>railway</th>\n",
       "      <th>tnc</th>\n",
       "      <th>internet</th>\n",
       "      <th>birla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message Category  visiting  mist  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...      ham       0.0   0.0   \n",
       "1                     [ok, lar, joking, wif, u, oni]      ham       0.0   0.0   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...     spam       0.0   0.0   \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...      ham       0.0   0.0   \n",
       "4  [nah, i, don, t, think, he, goes, to, usf, he,...      ham       0.0   0.0   \n",
       "\n",
       "   timing  flowing  spoilt  torch  jod  stream  ...  msn  doggin  abta  use  \\\n",
       "0     0.0      0.0     0.0    0.0  0.0     0.0  ...  0.0     0.0   0.0  0.0   \n",
       "1     0.0      0.0     0.0    0.0  0.0     0.0  ...  0.0     0.0   0.0  0.0   \n",
       "2     0.0      0.0     0.0    0.0  0.0     0.0  ...  0.0     0.0   0.0  0.0   \n",
       "3     0.0      0.0     0.0    0.0  0.0     0.0  ...  0.0     0.0   0.0  0.0   \n",
       "4     0.0      0.0     0.0    0.0  0.0     0.0  ...  0.0     0.0   0.0  0.0   \n",
       "\n",
       "   07808726822  grace  railway  tnc  internet  birla  \n",
       "0          0.0    0.0      0.0  0.0       0.0    0.0  \n",
       "1          0.0    0.0      0.0  0.0       0.0    0.0  \n",
       "2          0.0    0.0      0.0  0.0       0.0    0.0  \n",
       "3          0.0    0.0      0.0  0.0       0.0    0.0  \n",
       "4          0.0    0.0      0.0  0.0       0.0    0.0  \n",
       "\n",
       "[5 rows x 7742 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2- counting the number of words in each message and merge this into the training dataframe..\n",
    "word_counts_per_sms={unique_word: [0]*len(training_set['Message']) for unique_word in vocab}\n",
    "for idx, lst in enumerate(training_set['Message']):\n",
    "    for word in lst:\n",
    "        word_counts_per_sms[word][idx] +=1\n",
    "word_counter=pd.DataFrame(word_counts_per_sms)\n",
    "training_set_clean = pd.concat([training_set, word_counter], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965988c",
   "metadata": {
    "papermill": {
     "duration": 0.03084,
     "end_time": "2022-03-27T15:15:20.214957",
     "exception": false,
     "start_time": "2022-03-27T15:15:20.184117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1> Naïve Bayes Algorithm </h1>\n",
    "\n",
    "<img src = 'https://latex.codecogs.com/gif.latex?\\boldsymbol{\\mathbf{P(Spam%20|%20w_1,w_2,%20...,%20w_n)%20\\propto%20P(Spam)%20\\cdot%20\\prod_{i=1}^{n}P(w_i|Spam)}}'>\n",
    "<img src = 'https://latex.codecogs.com/gif.latex?\\boldsymbol{\\mathbf{P(Ham%20|%20w_1,w_2,%20...,%20w_n)%20\\propto%20P(Ham)%20\\cdot%20\\prod_{i=1}^{n}P(w_i|Ham)}}'>\n",
    "\n",
    "<p>our multinomial Naive Bayes algorithm will make the classification based on the results it gets to these two equations below, where \"w1\" is the first word, and w1,w2, ..., wn is the entire message .</p>\n",
    "<p>If P(Spam | w1,w2, ..., wn) > P(Ham | w1,w2, ..., wn), then the message is spam.</p>\n",
    "<p>To calculate P(wi|Spam) and P(wi|Ham)</p>\n",
    "<img src = 'https://latex.codecogs.com/gif.latex?\\boldsymbol{\\mathbf{P(w_i|Spam)%20=%20\\frac{N_{w_i|Spam}%20+%20\\alpha}{N_{Spam}%20+%20\\alpha%20\\cdot%20N_{Vocabulary}}}}'>\n",
    "<img src = 'https://latex.codecogs.com/gif.latex?\\boldsymbol{\\mathbf{P(w_i|Ham)%20=%20\\frac{N_{w_i|Ham}%20+%20\\alpha}{N_{Ham}%20+%20\\alpha%20\\cdot%20N_{Vocabulary}}}}'>\n",
    "<p> N(W(i) | Spam): the number of times the word W(i) occurs in spam message. </p>\n",
    "<p> N(W(i) | Ham): the number of times the word W(i) occurs in Ham message. </p>\n",
    "<p> N(Spam): number of words in Spam messages.</p> \n",
    "<p> N(Ham): number of words in Ham messages.</p> \n",
    "<p> N(vocab): number of words in vocabulary.</p>\n",
    "<p> alpha: equal to 1 called smothing parameter.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6cbe6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:20.279737Z",
     "iopub.status.busy": "2022-03-27T15:15:20.278974Z",
     "iopub.status.idle": "2022-03-27T15:15:20.290563Z",
     "shell.execute_reply": "2022-03-27T15:15:20.291070Z",
     "shell.execute_reply.started": "2022-03-27T14:35:14.464687Z"
    },
    "papermill": {
     "duration": 0.045878,
     "end_time": "2022-03-27T15:15:20.291265",
     "exception": false,
     "start_time": "2022-03-27T15:15:20.245387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of spam messages in Training DataFrame:  598\n",
      "number of ham messages in Training DataFrame:  3859\n",
      "probability of spam messages in Training DataFrame:  0.13417096701817366\n",
      "probability of ham messages in Training DataFrame:  0.8658290329818263\n"
     ]
    }
   ],
   "source": [
    "# 1- what is the probability of Spam and Ham messages in Training/Testing Dataset\n",
    "spam_length = len(training_set[training_set['Category'] == 'spam'])\n",
    "ham_length = len(training_set[training_set['Category'] == 'ham'])\n",
    "print('number of spam messages in Training DataFrame: ', spam_length)\n",
    "print('number of ham messages in Training DataFrame: ', ham_length)\n",
    "p_spam = spam_length / len(training_set)\n",
    "p_ham = ham_length / len(training_set)\n",
    "print('probability of spam messages in Training DataFrame: ', p_spam)\n",
    "print('probability of ham messages in Training DataFrame: ', p_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61dfdb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:15:20.356684Z",
     "iopub.status.busy": "2022-03-27T15:15:20.355668Z",
     "iopub.status.idle": "2022-03-27T15:27:05.493072Z",
     "shell.execute_reply": "2022-03-27T15:27:05.492010Z",
     "shell.execute_reply.started": "2022-03-27T14:35:14.479056Z"
    },
    "papermill": {
     "duration": 705.171073,
     "end_time": "2022-03-27T15:27:05.493426",
     "exception": false,
     "start_time": "2022-03-27T15:15:20.322353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2- what is the value of the liklihood probability of message when Spam/Ham is True\n",
    "n_words_spam_message = training_set[training_set['Category'] == 'spam']['Message'].apply(len)\n",
    "n_words_ham_message = training_set[training_set['Category'] == 'ham']['Message'].apply(len)\n",
    "#N(spam)\n",
    "n_spam = n_words_spam_message.sum()\n",
    "#N(Ham)\n",
    "n_ham = n_words_ham_message.sum()\n",
    "##\n",
    "spam_dict={word:0 for word in vocab}\n",
    "ham_dict={word:0 for word in vocab}\n",
    "alpha = 1\n",
    "for word in vocab:\n",
    "    # N(W(i) | Spam)\n",
    "    n_word_given_spam = training_set_clean[training_set_clean['Category'] == 'spam'][word].sum()\n",
    "    # P(W(i) | Spam)\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * len(vocab))\n",
    "    spam_dict[word] = p_word_given_spam\n",
    "    n_word_given_ham = training_set_clean[training_set_clean['Category'] == 'ham'][word].sum()\n",
    "    # P(W(i) | Ham)\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * len(vocab))\n",
    "    ham_dict[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd953026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:27:05.567211Z",
     "iopub.status.busy": "2022-03-27T15:27:05.566418Z",
     "iopub.status.idle": "2022-03-27T15:27:05.567926Z",
     "shell.execute_reply": "2022-03-27T15:27:05.568425Z",
     "shell.execute_reply.started": "2022-03-27T15:10:56.897502Z"
    },
    "papermill": {
     "duration": 0.041872,
     "end_time": "2022-03-27T15:27:05.568590",
     "exception": false,
     "start_time": "2022-03-27T15:27:05.526718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's write a function to classify messages based on the probability of word given spam/ham\n",
    "def bayes_filter(message):\n",
    "    # text processing\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    # set p_spam_given_word / set_ham_given_word equal to p spam and p ham\n",
    "    p_spam_given_word = p_spam\n",
    "    p_ham_given_word = p_ham\n",
    "    for word in message:\n",
    "        if word in spam_dict.keys() or word in ham_dict.keys():\n",
    "            p_spam_given_word *= spam_dict[word]\n",
    "            p_ham_given_word *= ham_dict[word]\n",
    "    print('P(Spam | W) = ', p_spam_given_word)\n",
    "    print('P(Ham | W) = ', p_ham_given_word)\n",
    "    if p_spam_given_word > p_ham_given_word:\n",
    "        print('Category: Spam')\n",
    "    elif p_spam_given_word < p_ham_given_word:\n",
    "        print('Category: Ham')\n",
    "    else:\n",
    "        print('Maybe one of Them.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db291894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:27:05.632401Z",
     "iopub.status.busy": "2022-03-27T15:27:05.631723Z",
     "iopub.status.idle": "2022-03-27T15:27:05.638276Z",
     "shell.execute_reply": "2022-03-27T15:27:05.638949Z",
     "shell.execute_reply.started": "2022-03-27T15:10:59.998656Z"
    },
    "papermill": {
     "duration": 0.039953,
     "end_time": "2022-03-27T15:27:05.639125",
     "exception": false,
     "start_time": "2022-03-27T15:27:05.599172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam | W) =  5.285960360968486e-37\n",
      "P(Ham | W) =  1.7090184267541062e-33\n",
      "Category: Ham\n"
     ]
    }
   ],
   "source": [
    "bayes_filter('U dun say so early hor... U c already then say')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da6210e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:27:05.702999Z",
     "iopub.status.busy": "2022-03-27T15:27:05.702348Z",
     "iopub.status.idle": "2022-03-27T15:27:05.707437Z",
     "shell.execute_reply": "2022-03-27T15:27:05.708390Z",
     "shell.execute_reply.started": "2022-03-27T15:11:02.797737Z"
    },
    "papermill": {
     "duration": 0.039089,
     "end_time": "2022-03-27T15:27:05.708713",
     "exception": false,
     "start_time": "2022-03-27T15:27:05.669624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam | W) =  7.225048739561725e-25\n",
      "P(Ham | W) =  8.50585359063866e-22\n",
      "Category: Ham\n"
     ]
    }
   ],
   "source": [
    "bayes_filter(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f2b82b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:27:05.775372Z",
     "iopub.status.busy": "2022-03-27T15:27:05.774669Z",
     "iopub.status.idle": "2022-03-27T15:27:05.780618Z",
     "shell.execute_reply": "2022-03-27T15:27:05.781250Z",
     "shell.execute_reply.started": "2022-03-27T15:13:49.778806Z"
    },
    "papermill": {
     "duration": 0.04059,
     "end_time": "2022-03-27T15:27:05.781429",
     "exception": false,
     "start_time": "2022-03-27T15:27:05.740839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bayes_classifier(message):\n",
    "    # text processing\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    # set p_spam_given_word / set_ham_given_word equal to p spam and p ham\n",
    "    p_spam_given_word = p_spam\n",
    "    p_ham_given_word = p_ham\n",
    "    for word in message:\n",
    "        if word in spam_dict.keys() or word in ham_dict.keys():\n",
    "            p_spam_given_word *= spam_dict[word]\n",
    "            p_ham_given_word *= ham_dict[word]\n",
    "    if p_spam_given_word > p_ham_given_word:\n",
    "        return 'spam'\n",
    "    elif p_spam_given_word < p_ham_given_word:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'maybe both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77b9f223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:27:05.881847Z",
     "iopub.status.busy": "2022-03-27T15:27:05.863332Z",
     "iopub.status.idle": "2022-03-27T15:27:05.884918Z",
     "shell.execute_reply": "2022-03-27T15:27:05.885502Z",
     "shell.execute_reply.started": "2022-03-27T15:14:00.200434Z"
    },
    "papermill": {
     "duration": 0.073311,
     "end_time": "2022-03-27T15:27:05.885678",
     "exception": false,
     "start_time": "2022-03-27T15:27:05.812367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Category</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>squeeeeeze   this is christmas hug   if u lik ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>and also i ve sorta blown him off a couple tim...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>mmm thats better now i got a roast down me  i ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>mm have some kanji dont eat anything heavy ok</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>so there s a ring that comes with the guys cos...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Message Category predicted\n",
       "3245  squeeeeeze   this is christmas hug   if u lik ...      ham       ham\n",
       "944   and also i ve sorta blown him off a couple tim...      ham       ham\n",
       "1044  mmm thats better now i got a roast down me  i ...      ham       ham\n",
       "2484      mm have some kanji dont eat anything heavy ok      ham       ham\n",
       "812   so there s a ring that comes with the guys cos...      ham       ham"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set['predicted'] = testing_set['Message'].apply(bayes_classifier)\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d7a2c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:27:06.007301Z",
     "iopub.status.busy": "2022-03-27T15:27:05.970706Z",
     "iopub.status.idle": "2022-03-27T15:27:06.025787Z",
     "shell.execute_reply": "2022-03-27T15:27:06.026472Z",
     "shell.execute_reply.started": "2022-03-27T15:14:28.238724Z"
    },
    "papermill": {
     "duration": 0.109229,
     "end_time": "2022-03-27T15:27:06.026718",
     "exception": false,
     "start_time": "2022-03-27T15:27:05.917489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 964\n",
      "Incorrect: 151\n",
      "Accuracy: 0.8645739910313901\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = testing_set.shape[0]\n",
    "    \n",
    "for row in testing_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Category'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250dfeb",
   "metadata": {
    "papermill": {
     "duration": 0.032397,
     "end_time": "2022-03-27T15:27:06.091373",
     "exception": false,
     "start_time": "2022-03-27T15:27:06.058976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 734.680435,
   "end_time": "2022-03-27T15:27:07.137719",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-27T15:14:52.457284",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
